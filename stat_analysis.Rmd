---
title: "Statistical Analysis"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
library(tidyverse)
library(patchwork)
library(gtsummary)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```



## Dataset Overview

In this first step, we wrangle the data such that it is usable and provide a brief overview of our dataset and our variables of interest. In particular, we create anoth

```{r}
library(readr)
# dt = read_csv("data/inspection_sub_all_date.csv")
df = read_csv("data/inspection_sub_latest_date.csv") %>%
  distinct(camis, .keep_all = TRUE) %>%  # s.t. each row contains info for one restaurant
  mutate(price = fct_recode(price, "1" = "$", "2" = "$$", "3" = "$$$", "4" = "$$$$"),
         boro = fct_reorder(boro, rating),
         grade = fct_relevel(grade, "A"),
         )
```

Now, we provide a table summary of all variables involved.

```{r}
df %>% 
  select(boro, score, grade, rating, review_num, price) %>% 
  tbl_summary(
    missing_text = "(Missing)", 
    statistic = list(
      all_continuous() ~ "{mean} ({sd})", 
      all_categorical() ~ "{n} ({p}%)"
      )) %>% 
  bold_labels() %>%   
  italicize_levels() 
```

* We can see that Manhattan has the most restaurants (40% of all restaurants in the city), followed by Brooklyn (28%), Queens (22%), Bronx (6.6%), and Staten Island (3.4%).
* The "score" variable has 100 missing values with mean 18 and standard deviation 14.
* The "grade" variable has 1,399 missing values with most of the restaurants receiving As (70% of all restaurants).
* Each restaurant has average rating 3.78 with standard deviation 0.68.
* Each restaurant has on average 232 reviews with standard deviation 485.
* The most common price range for restaurants is between \$11-\$30 (60%), followed by under \$10 (31%).

### Chi-square Test

#### Inspection Grades and Boroughs

We try to determine whether there is a relationship between boroughs and restaurants' inspection grades. Our hypothesis is that there is no difference in the number of restaurants across the five grades across the five boroughs in NYC. We will perform the chi-square test to verify our assumption.

$H0$: the expected number of restaurants in each grades are the same across all boroughs.

$H1$: the expected number of restaurants in each grades are not same across all boroughs.

```{r}
grade_boro = 
  df %>% 
  drop_na(grade) %>% 
  count(boro, grade) %>% 
  pivot_wider(
    names_from = "grade",
    values_from = "n") %>%
  replace(is.na(.), 0) %>% 
  data.matrix() %>%
  subset(select = -c(boro))

rownames(grade_boro) <- c("Bronx", "Staten Island", "Queens", "Brooklyn", "Manhattan")

grade_boro %>% 
  knitr::kable(caption = "Results Table")

# chi-square test.
chisq.test(grade_boro)
```

Interpretation: The result of chi-square shows that p-value is less than 0.05, so we reject the null hypothesis at 95% significant level and conclude that the inspection grades of restaurants are significantly different by boroughs. 

```{r}
price_grade = df %>% 
  select(boro, score, grade, rating, review_num, price) %>%
  drop_na(price, grade) %>% 
  group_by(price, grade) %>% 
  summarise(n = n()) %>% 
  pivot_wider(
    names_from = grade,
    values_from = n 
  ) %>% 
  replace(is.na(.), 0) %>% 
  data.matrix() %>%
  subset(select = -c(price))

rownames(price_grade) <- c("$", "$$", "$$$", "$$$$")

price_grade %>% 
  knitr::kable(caption = "Results Table")

chisq.test(price_grade)
```

Interpretation: The result of chi-square shows that p-value is less than 0.05, so we reject the null hypothesis at 95% significant level and conclude that the inspection grades of restaurants are significantly different by price scales of restaurants.


## Proportion Test

Now, we want to see whether receiving grade A is equally common among restaurants of all four price scales. To do this, we will conduct a proportion test.

```{r}
total = df %>% 
  group_by(price) %>% 
  summarise(total = n())

n_a = df %>% 
  count(price, grade) %>% 
  filter(grade == "A")

join = left_join(total, n_a) %>% drop_na()
prop.test(join$n, join$total)

#join = join %>% 
 # mutate(prop = n/total) %>% 
 # select(price, prop)
```

## Regression model

We first wrangle the data such that each restaurant only represent one row in the dataset.



### Regression Diagnostics

To perform any regression model, we first perform test of normality on the response variable, ratings. We first plot a histogram on the data, from which we can see that the response variable is not exactly normally distributed and slightly skewed to the left. We confirm this deviation from normality by conducting the Kolmogorov-Smirnov test for normality. To adjust for this factor, we transform the rating variable by squaring it. As we may see in the histogram, the square-adjusted variable is approximately normal.

```{r}
# plot histogram
hist(df$rating)

# Kolmogorov-Smirnov test
ks.test(df$rating, 'pnorm')

# plot histogram for square-transformed data
hist(df$rating^2)
```

Now, we perform diagnostic tests required for regression models.

```{r}
df %>% 
  select(boro, score, grade, rating, review_num, price) %>%
  summary()

lm(rating^2 ~ , data = df)
```

### Choosing the "Best" Model
