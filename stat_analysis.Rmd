---
title: "Statistical Analysis"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
library(tidyverse)
library(patchwork)
library(gtsummary)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```



## Dataset Overview

In this first step, we wrangle the data such that it is usable and provide a brief overview of our dataset and our variables of interest. In particular, we create anoth

```{r}
library(readr)
# dt = read_csv("data/inspection_sub_all_date.csv")
df = read_csv("data/inspection_sub_latest_date.csv") %>%
  mutate(price = fct_recode(price, "1" = "$", "2" = "$$", "3" = "$$$", "4" = "$$$$"),
         boro = fct_reorder(boro, rating),
         grade = fct_relevel(grade, "A")) %>%
  group_by(camis) %>%
  mutate(percent_critical = sum(critical_flag == "Critical")/n())

df <- df %>% distinct(camis, .keep_all = TRUE)
```

Now, we provide a table summary of all variables involved.

```{r}
df %>% 
  select(boro, score, grade, rating, review_num, price) %>% 
  tbl_summary(
    missing_text = "(Missing)", 
    statistic = list(
      all_continuous() ~ "{mean} ({sd})", 
      all_categorical() ~ "{n} ({p}%)"
      )) %>% 
  bold_labels() %>%   
  italicize_levels() 
```

* We can see that Manhattan has the most restaurants (40% of all restaurants in the city), followed by Brooklyn (28%), Queens (22%), Bronx (6.6%), and Staten Island (3.4%).
* The "score" variable has 100 missing values with mean 18 and standard deviation 14.
* The "grade" variable has 1,399 missing values with most of the restaurants receiving As (70% of all restaurants).
* Each restaurant has average rating 3.78 with standard deviation 0.68.
* Each restaurant has on average 232 reviews with standard deviation 485.
* The most common price range for restaurants is between \$11-\$30 (60%), followed by under \$10 (31%).

### Chi-square Test

#### Inspection Grades and Boroughs

We try to determine whether there is a relationship between boroughs and restaurants' inspection grades. Our hypothesis is that there is no difference in the number of restaurants across the five grades across the five boroughs in NYC. We will perform the chi-square test to verify our assumption.

$H0$: the expected number of restaurants in each grades are the same across all boroughs.

$H1$: the expected number of restaurants in each grades are not same across all boroughs.

```{r}
grade_boro = 
  df %>% 
  drop_na(grade) %>% 
  count(boro, grade) %>% 
  pivot_wider(
    names_from = "grade",
    values_from = "n") %>%
  replace(is.na(.), 0) %>% 
  data.matrix() %>%
  subset(select = -c(boro))

rownames(grade_boro) <- c("Bronx", "Staten Island", "Queens", "Brooklyn", "Manhattan")

grade_boro %>% 
  knitr::kable(caption = "Results Table")

# chi-square test.
chisq.test(grade_boro)
```

Interpretation: The result of chi-square shows that p-value is less than 0.05, so we reject the null hypothesis at 95% significant level and conclude that the inspection grades of restaurants are significantly different by boroughs. 

```{r}
price_grade = df %>% 
  select(boro, score, grade, rating, review_num, price) %>%
  drop_na(price, grade) %>% 
  group_by(price, grade) %>% 
  summarise(n = n()) %>% 
  pivot_wider(
    names_from = grade,
    values_from = n 
  ) %>% 
  replace(is.na(.), 0) %>% 
  data.matrix() %>%
  subset(select = -c(price))

rownames(price_grade) <- c("$", "$$", "$$$", "$$$$")

price_grade %>% 
  knitr::kable(caption = "Results Table")

chisq.test(price_grade)
```

Interpretation: The result of chi-square shows that p-value is less than 0.05, so we reject the null hypothesis at 95% significant level and conclude that the inspection grades of restaurants are significantly different by price scales of restaurants.


## Proportion Test

Now, we want to see whether receiving grade A is equally common among restaurants of all four price scales. To do this, we will conduct a proportion test.

```{r}
total = df %>% 
  group_by(price) %>% 
  summarise(total = n())

n_a = df %>% 
  count(price, grade) %>% 
  filter(grade == "A")

join = left_join(total, n_a) %>% drop_na()
prop.test(join$n, join$total)

#join = join %>% 
 # mutate(prop = n/total) %>% 
 # select(price, prop)
```


## Regression model

In this step, we perform multiple linear regression (MLR) to ascertain the optimal model for predicting Yelp rating.

### Data Wrangling and Transformation

In this step, we check whether our data satisfies the normality assumptions for multiple linear regression and perform transformations to fit the assumptions if unsatisfied.

```{r}
# sided qq-plot for each untransformed numeric variable
par(mfrow = c(2, 2))
qqplot(qnorm(pp))

# log transform percent_critical, score, and review_num, square-transform 
reg_df = df %>% 
  select(boro, score, rating, review_num, price, percent_critical) 
```
