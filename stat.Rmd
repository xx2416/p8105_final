---
title: "Statistical Analysis"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
library(tidyverse)
library(patchwork)
library(gtsummary)

knitr::opts_chunk$set(
  warning = FALSE, 
  message = FALSE,
  error = FALSE,
  fig.width = 6,
  fig.asp = .9,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

library(readr)
# dt = read_csv("data/inspection_sub_all_date.csv")
df = read_csv("data/inspection_sub_latest_date.csv") %>%
  mutate(price = fct_recode(price, "1" = "$", "2" = "$$", "3" = "$$$", "4" = "$$$$"),
         boro = fct_reorder(boro, rating),
         grade = fct_relevel(grade, "A")) %>%
  group_by(camis) %>%
  mutate(percent_critical = sum(critical_flag == "Critical")/n())

# Make distinction such that each restaurant is its unique row.
df <- df %>% 
  distinct(camis, .keep_all = TRUE) %>%
  ungroup()
```


## Regression model

Now, we perform regression analysis from our data treating "rating" as the response variable of interest.

### Data Wrangling and Transformation

In this step, we check whether our data satisfies the normality assumptions for multiple linear regression and perform transformations to fit the assumptions if unsatisfied.

```{r}
# sided histogram for each untransformed numeric variable
par(mfrow = c(2, 2))
hist(df$rating, main = "Histogram for Rating", xlab = "rating", ylab = "frequency")
hist(df$score, main = "Histogram for Score", xlab = "rating", ylab = "frequency")
hist(df$review_num, main = "Histogram for Number of Reviews", xlab = "rating", ylab = "frequency")
hist(df$percent_critical, main = "Histogram for Percentage of Flags Critical", xlab = "rating", ylab = "frequency")
```

As shown in the histograms, rating is severely positively-skewed, percent_critical_flag is slightly positively skewed, score is moderately positively-skewed, and rating is negatively skewed. However, MLR only requires the assumption that the response variable be normally distributed. Therefore, we square-transform the rating variable and use a QQ plot to confirm that normality is not severely violated.

```{r}
# square-transform rating
reg_df = df %>% 
  filter(!is.na(score)) %>%
  mutate(sq_rating = rating^2) %>%
  ungroup() %>%
  select(sq_rating, boro, score, review_num, price, percent_critical) 

# side-by-side qq-plot for transformed numeric variables
qqnorm(reg_df$sq_rating, main = "Normal QQ Plot: Squared Rating", pch = 0.01, frame = FALSE)
qqline(reg_df$sq_rating, col = "steelblue")
```

### Selecting Model Based on Predictor Prognosis

Next, we check for correlation between continuous independent variables and interaction between other independent variables.

```{r}
library("ggplot2")                     
library("GGally")

reg_df %>% 
  ggpairs() + theme_bw()
```

Thus, we expect review_num, percent_critical, price, and boro to be significant predictors for sq_rating. For continuous independent variables, we expect statistically significant correlation between score and percent_critical. Now, we assess the interaction between review_num and price range; review_num and boro; percent_critical and price range; and percent_critical and boro.

```{r}
# review_num and price
p1 = reg_df %>% 
  ggplot(aes(x = review_num, y = sq_rating, color = price)) +
  geom_point() +
  geom_smooth(method="lm", se=F, aes(group = price, color = price))
# review_num and boro
p2 = reg_df %>% 
  ggplot(aes(x = review_num, y = sq_rating, color = boro)) +
  geom_point() +
  geom_smooth(method="lm", se=F, aes(group = boro, color = boro))
# percent_critical and price
p3 = reg_df %>%
  ggplot(aes(x = percent_critical, y = sq_rating, color = price)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = F, aes(group = price, color = price))
# percent_critical and boro
p4 = reg_df %>%
  ggplot(aes(x = percent_critical, y = sq_rating, color = boro)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = F, aes(group = boro, color = boro))

# Display results
p1+p2+p3+p4
```

As such, we observe strong interaction between review_num, borough, and price; but little interaction between percent_critical and price or percent_critical and borough. Therefore, we fit our first model with interaction of review_num, borough, and price along with percent_critical.

```{r}
fit_1 = lm(sq_rating ~ price * review_num + boro + percent_critical, data = reg_df)

# display results
fit_1 %>% broom::tidy() %>% knitr::kable(digits = 4)
```

### Criterion-Based Approach and Backward Elimination to Model Selection

We now turn our attention to formal methods of choosing optimal model. Since the number of our predictor is not huge, we employ a criterion-based approach to select independent variables.

```{r}
library(leaps)
b = regsubsets(sq_rating ~ ., data = reg_df)
rs = summary(b)
par(mfrow = c(2, 2))
plot(rs$rss, xlab = "Number of Variables", ylab = "RSS", type = "b")
plot(rs$adjr2, xlab = "Number of Variables", ylab = "Adjusted RSq", type = "b")
best_adj_r2 = which.max(rs$adjr2) # 4 (index)
points(best_adj_r2, rs$adjr2[best_adj_r2], # point(x, y)
       col = "red",cex = 2, pch = 20)
plot(rs$cp, xlab = "Number of Variables", ylab = "Cp", type = 'b')
best_cp = which.min(rs$cp)
points(best_cp, rs$cp[best_cp], 
       col = "red", cex = 2, pch = 20)
plot(rs$bic, xlab = "Number of Variables", ylab = "BIC", type = 'b')
best_bic = which.min(rs$bic)
points(best_bic, rs$bic[best_bic], 
       col = "red", cex = 2, pch = 20)
```

As such, both the Cp criterion and the Adjusted $R^2$ suggests that we should consider all parameters. We fit a model accounting for all independent variables in the regression dataset.

```{r}
fit_2 <- lm(sq_rating ~ ., data = reg_df)
fit_2 %>% broom::tidy() %>% knitr::kable(digits = 4)
```

Finally, since the "score" variable comes out to be not significantly correlated with the response variable sq_rating under any circumstances, we consider the backwards approach to see eliminating it would create more efficiency for the model.

```{r}
step(fit_2, direction = "backward") 
```

In this way, we fit this model selected by the backwards approach. From the results of this model shown below, all predictors are significant except the boro of Staten Island.

```{r}
fit_3 <- lm(sq_rating ~ boro + review_num + price + percent_critical, data = reg_df)

# display result
fit_3 %>% broom::tidy() %>% knitr::kable(digits = 4)
```

### Cross Validation

#### Model Comparison

In this step, we perform cross-validation to compare our three models in terms of cross-validation prediction error.

```{r fig.height=3}
library(modelr)
set.seed(1)
cv_df <- crossv_mc(reg_df, n = 100) %>%
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) %>% 
  mutate(
    fit_1 = map(train, ~lm(sq_rating ~ price * review_num + boro + percent_critical, data = .x)),
    fit_2 = map(train, ~lm(sq_rating ~ ., data = .x)),
    fit_3 = map(train, ~lm(sq_rating ~ boro + review_num + price + percent_critical, data = .x))
  ) %>%
  mutate(
    rmse_fit_1 = map2_dbl(fit_1, test, ~rmse(model = .x, data = .y)),
    rmse_fit_2 = map2_dbl(fit_2, test, ~rmse(model = .x, data = .y)),
    rmse_fit_3 = map2_dbl(fit_3, test, ~rmse(model = .x, data = .y))
  )

# Display RMSE results
cv_df %>% 
  summarise(fit1_mean_error = mean(rmse_fit_1),
            fit2_mean_error = mean(rmse_fit_2),
            fit3_mean_error = mean(rmse_fit_3)) %>%
  knitr::kable(digits = 3)

# Show the distribution of RMSEs using violin plots
cv_df %>%
  select(starts_with("rmse")) %>%
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse") %>%
  mutate(model = fct_inorder(model)) %>%
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin()
```

#### Elastic Net

As seen, fit_1 has the least RMSE compared to all other models. Therefore, we use this model for further training using elastic net.

```{r}
library(glmnet)
library(caret)
set.seed(2)
cv_10 = trainControl(method = "cv", number = 10)
x = model.matrix(~ ., dplyr::select(reg_df, -sq_rating))[,-1]
y = reg_df$sq_rating
elnet_int = train(
  sq_rating ~ price * review_num + boro + percent_critical, data = reg_df %>% drop_na(),
  method = "glmnet",
  trControl = cv_10,
  tuneLength = 10
)
get_best_result = function(caret_fit) {
  best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
  best_result = caret_fit$results[best, ]
  rownames(best_result) = NULL
  best_result
}
get_best_result(elnet_int)
```

### Model Diagnostics

In this final step, we perform model diagnostics to see if assumptions are satisfied for our chosen, optimal model. Specifically, we assess whether our model of choice violates the assumptions of linear regression model, including multicollinearity by using VIF values, non-linearity, unequal error variances.

#### Residual vs. Fitted Plot

```{r}
# Plot model residuals against fitted values
par(mfrow = c(2, 2))
plot(fit_1, which = 1)
plot(fit_1, which = 2)
plot(fit_1, which = 3)
plot(fit_1, which = 4)
```

1. The residuals do not "bounce randomly" around the 0 line, suggesting that the assumption that the relationship is linear is not reasonable.

2. The residuals do not roughly form a "horizontal band" around 0, which suggests violations for equal variance assumption.

3. There are a few outliers in our plot, suggesting there are influential points or outliers.

#### Multicolinearity

Since our optimal model contains interaction terms, which may inflate VIF, we check for fit_2, which includes all predictor variables and no interaction terms.

```{r}
library(performance)
multicollinearity(fit_2) %>% as_tibble() %>% knitr::kable(digits = 4)
```

As such, we may be confident in saying that there is no significant violation for collinearity assumption.
